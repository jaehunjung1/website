<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jaehun Jung</title>

    <meta name="author" content="Jaehun Jung">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jaehun Jung
                </p>
                <p>I'm a Ph.D student in computer science at the <a href="https://www.cs.washington.edu/">University of Washington</a>, advised by <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>. My research focuses on generating high-quality data from language models, improving their reliability and controllability with minimal human supervision.
                </p>
                <p>
                  Previously I was an undergrad at Seoul National University, advised by Professor <a href="https://datalab.snu.ac.kr/~ukang/">U Kang</a> and <a href="http://hcil.snu.ac.kr/people/jinwook-seo">Jinwook Seo</a>. I was also a part-time researcher in Kakao Enterprise, where I worked on knowledge-grounded dialogue agents.
                </p>
                <p style="text-align:center">
                  <a href="mailto:hoony123@cs.washingon.edu">Email</a> &nbsp;/&nbsp;
                  <a href="data/JaehunJung_CV.pdf">CV</a> &nbsp;/&nbsp;
<!--                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;-->
                  <a href="https://scholar.google.com/citations?user=_bXzUGEAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/jaehunjung_com">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jaehunjung1/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/profile.png"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/profile.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:10px;width:100%;vertical-align:middle">
                <h2>Research</h2>
<!--                <p>-->
<!--                  I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about inferring the physical world (shape, motion, color, light, etc) from images, usually with radiance fields. Representative papers are <span class="highlight">highlighted</span>.-->
<!--                </p>-->
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='infosumm_image' />
          <img src='images/infosumm.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/pdf/2403.13780">
          <span class="papertitle">Information-Theoretic Distillation for Reference-less Summarization</span>
        </a>
        <br>
        <strong>Jaehun Jung</strong>,
        <a href="https://www.linkedin.com/in/ximing-lu-4aa9a51a0/">Ximing Lu</a>,
        <a href="https://liweijiang.me/">Liwei Jiang</a>,
        <a href="https://fabrahman.github.io/">Faeze Brahman</a>,
        <a href="https://homes.cs.washington.edu/~pawest/">Peter West</a>,
        <a href="https://koh.pw/">Pang Wei Koh</a>,
        <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>
        <br>
        <em>preprint</em>, 2024
        <br>
        <a href="https://arxiv.org/pdf/2403.13780">paper</a>
        /
        <a href="data/infosumm.bib">bibtex</a>
        <p></p>
        <p>
          Can small models excel at summarization without LLM or human-written references? We present InfoSumm, a framework to distill a powerful summarizer that outperforms order-of-magnitude larger LLM summarizers, solely based on the information-theoretic objective for summarization.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='impossible_distillation_image' />
          <img src='images/impossible_distillation.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2305.16635">
          <span class="papertitle">Impossible Distillation for Paraphrasing and Summarization: How to Make High-quality Lemonade out of Small, Low-quality Models</span>
        </a>
        <br>
        <strong>Jaehun Jung</strong>,
        <a href="https://homes.cs.washington.edu/~pawest/">Peter West</a>,
        <a href="https://liweijiang.me/">Liwei Jiang</a>,
        <a href="https://fabrahman.github.io/">Faeze Brahman</a>,
        <a href="https://www.linkedin.com/in/ximing-lu-4aa9a51a0/">Ximing Lu</a>,
        <a href="https://jillianfisher.owlstown.net/">Jillian Fisher</a>,
        <a href="https://tsor13.github.io/">Taylor Sorensen</a>,
        <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>
        <br>
        <em>NAACL</em>, 2024
        <br>
        <a href="https://arxiv.org/pdf/2305.16635">paper</a>
        /
        <a href="https://huggingface.co/datasets/Jaehun/DIMSUM">data</a>
        /
        <a href="data/impossible_distillation.bib">bibtex</a>
        <p></p>
        <p>
          It is possible to generate a high-quality dataset for sentential paraphrasing and summarization directly from an off-the-shelf LM, even when it is impossible for the LM itself to reliably solve the task.
        </p>
      </td>
    </tr>



    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='jamdec_image' />
          <img src='images/jamdec.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2402.08761">
          <span class="papertitle">Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models</span>
        </a>
        <br>
        <a href="https://jillianfisher.owlstown.net/">Jillian Fisher</a>,
        <a href="https://www.linkedin.com/in/ximing-lu-4aa9a51a0/">Ximing Lu</a>,
        <strong>Jaehun Jung</strong>,
        <a href="https://liweijiang.me/">Liwei Jiang</a>,
        <a href="https://sites.google.com/uw.edu/zaid-harchaoui/main">Zaid Harchaoui</a>,
        <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>
        <br>
        <em>NAACL</em>, 2024 <strong style="color:red">(Oral Presentation)</strong>
        <br>
        <a href="https://arxiv.org/abs/2402.08761">paper</a>
        /
        <a href="https://github.com/jfisher52/JAMDecoding">github</a>
        /
        <a href="data/jamdec.bib">bibtex</a>
        <p></p>
        <p>
          We introduce JamDec, an inference-time algorithm for authorship obfuscation that is domain-agnostic, controllable, yet does not require human supervision.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ipa_image' />
          <img src='images/ipa.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://aclanthology.org/2023.emnlp-main.424/">
          <span class="papertitle">Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning</span>
        </a>
        <br>
        <a href="https://www.linkedin.com/in/ximing-lu-4aa9a51a0/">Ximing Lu</a>,
        <a href="https://fabrahman.github.io/">Faeze Brahman</a>,
        <a href="https://homes.cs.washington.edu/~pawest/">Peter West</a>,
        <strong>Jaehun Jung</strong>,
        ...
        <a href="https://www.seanre.com/">Xiang Ren</a>,
        <a href="https://wellecks.com/">Sean Welleck</a>,
        <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>
        <br>
        <em>EMNLP</em>, 2023
        <br>
        <a href="https://aclanthology.org/2023.emnlp-main.424.pdf">paper</a>
        /
        <a href="https://github.com/GXimingLu/IPA">github</a>
        /
        <a href="data/ipa.bib">bibtex</a>
        <p></p>
        <p>
          Can we adapt LLMs without fine-tuning? We propose using a lightweight adapter (e.g. GPT-2) during decoding time, efficiently tailoring even the strongest proprietary LLMs toward user-defined reward.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='steer_image' />
          <img src='images/steer.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://aclanthology.org/2023.findings-emnlp.506/">
         <span class="papertitle">STEER: Unified Style Transfer with Expert Reinforcement</span>
        </a>
        <br>
        <a href="https://skylerhallinan.com/">Skyler Hallinan</a>,
        <a href="https://fabrahman.github.io/">Faeze Brahman</a>,
        <a href="https://www.linkedin.com/in/ximing-lu-4aa9a51a0/">Ximing Lu</a>,
        <strong>Jaehun Jung</strong>,
        <a href="https://wellecks.com/">Sean Welleck</a>,
        <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>
        <br>
        <em>Findings of EMNLP</em>, 2023
        <br>
        <a href="https://aclanthology.org/2023.findings-emnlp.506.pdf">paper</a>
        /
        <a href="https://github.com/shallinan1/STEERStyleTransfer">github</a>
        /
        <a href="data/steer.bib">bibtex</a>
        <p></p>
        <p>
          We propose a text style transfer framework from arbitrary source style to many target styles via large-scale data generation with expert-guided decoding and offline RL.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='maieutic_prompting_image' />
          <img src='images/maieutic_prompting.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://aclanthology.org/2022.emnlp-main.82/">
    <span class="papertitle">Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations</span>
        </a>
        <br>
        <strong>Jaehun Jung</strong>,
        <a href="https://sites.google.com/view/lianhuiqin/home">Lianhui Qin</a>,
        <a href="https://wellecks.com/">Sean Welleck</a>,
        <a href="https://fabrahman.github.io/">Faeze Brahman</a>,
        <a href="https://www.chandrab.page/">Chandra Bhagavatula</a>,
        <a href="https://rlebras.github.io/">Ronan Le Bras</a>,
        <a href="https://homes.cs.washington.edu/~yejin/">Yejin Choi</a>
        <br>
        <em>EMNLP</em>, 2022 <strong style="color:red">(Oral Presentation)</strong>
        <br>
        <a href="https://aclanthology.org/2022.emnlp-main.82.pdf">paper</a>
        /
        <a href="https://github.com/jaehunjung1/Maieutic-Prompting">github</a>
        /
        <a href="data/maieutic_prompting.bib">bibtex</a>
        <p></p>
        <p>
          We improve LM reasoning by generating abductive and recursive explanations from language models, then formulating inference as a satisfiability problem over these generations.
        </p>
      </td>
    </tr>

    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='t-gap_image' />
          <img src='images/t-gap.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/10.1145/3447548.3467292">
          <span class="papertitle">Learning to Walk across Time for Interpretable Temporal Knowledge Graph Completion</span>
        </a>
        <br>
        <strong>Jaehun Jung</strong>,
        <a href="https://jinhongjung.github.io/">Jinhong Jung</a>,
        <a href="https://datalab.snu.ac.kr/~ukang/">U Kang</a>
        <br>
        <em>KDD</em>, 2021
        <br>
        <a href="https://jinhongjung.github.io/assets/resources/papers/tgapKDD21.pdf">paper</a>
        /
        <a href="https://github.com/jaehunjung1/T-GAP">github</a>
        /
        <a href="data/t-gap.bib">bibtex</a>
        <p></p>
        <p>
          A novel GNN for temporal KG is proposed that encodes an interpretable graph substructure for knowledge graph completion.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='attnio_image' />
          <img src='images/attnio.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://aclanthology.org/2020.emnlp-main.280/">
          <span class="papertitle">AttnIO: Knowledge Graph Exploration with In-and-Out Attention Flow for Knowledge-Grounded Dialogue</span>
        </a>
        <br>
        <strong>Jaehun Jung</strong>,
        Bokyung Son,
        Sungwon Lyu
        <br>
        <em>EMNLP</em>, 2020
        <br>
        <a href="https://aclanthology.org/2020.emnlp-main.280.pdf">paper</a>
        /
        <a href="https://slideslive.com/38938773">video</a>
        /
        <a href="data/attnio.bib">bibtex</a>
        <p></p>
        <p>
          We present a novel decoder model based on attention flow that learns to explore KG and retrieve a relevant knowledge path to ground a dialogue agent.
        </p>
      </td>
    </tr>


    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='datahalo_image' />
          <img src='images/datahalo.png' style="width:100%;position:absolute;top:0;bottom:0;margin:auto">
        </div>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://dl.acm.org/doi/full/10.1145/3544548.3580828">
          <span class="papertitle">DataHalo: A Customizable Notification Visualization System for Personalized and Longitudinal Interactions</span>
        </a>
        <br>
        <a href="https://kr.linkedin.com/in/guhyun-han-830215285">Guhyun Han</a>,
        <strong>Jaehun Jung</strong>,
        <a href="http://younghokim.net/">Youngho Kim</a>
        <a href="http://hcil.snu.ac.kr/people/jinwook-seo">Jinwook Seo</a>
        <br>
        <em>CHI</em>, 2023
        <br>
        <a href="https://dl.acm.org/doi/pdf/10.1145/3544548.3580828">paper</a>
        /
        <a href="data/datahalo.bib">bibtex</a>
        <p></p>
        <p>
          DataHalo implements a customizable notification visualization system for mobile devices, providing prolonged ambient visualizations based on time-varying importance model to enable longitudinal interaction with the notifications.
        </p>
      </td>
    </tr>


    </tbody></table>

          
<!--          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>-->
<!--            <tr>-->
<!--              <td>-->
<!--                <h2>Miscellanea</h2>-->
<!--              </td>-->
<!--            </tr>-->
<!--          </tbody></table>-->
<!--          <table width="100%" align="center" border="0" cellpadding="20"><tbody>-->
<!--            -->
<!--            <tr>-->
<!--              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>-->
<!--              <td width="75%" valign="center">-->
<!--                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>-->
<!--                <br>-->
<!--                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>-->
<!--                <br>-->
<!--                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>-->
<!--                <br>-->
<!--                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>-->
<!--                <br>-->
<!--                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>-->
<!--                <br>-->
<!--                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>-->
<!--              </td>-->
<!--            </tr>-->
<!--            <tr>-->
<!--              <td style="padding:20px;width:25%;vertical-align:middle">-->
<!--                <img src="images/cs188.jpg" alt="cs188">-->
<!--              </td>-->
<!--              <td width="75%" valign="center">-->
<!--                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>-->
<!--                <br>-->
<!--                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>-->
<!--                <br>-->
<!--                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>-->
<!--              </td>-->
<!--            </tr>-->
<!--            -->

<!--            <tr>-->
<!--              <td align="center" style="padding:20px;width:25%;vertical-align:middle">-->
<!--                <h2>Basically <br> Blog Posts</h2>-->
<!--              </td>-->
<!--              <td width="75%" valign="middle">-->
<!--                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>-->
<!--                <br>-->
<!--                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>-->
<!--                <br>-->
<!--                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>-->
<!--                <br>-->
<!--                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>-->
<!--              </td>-->
<!--            </tr>-->
<!--          </tbody></table>-->


          <br><br>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website design by <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
